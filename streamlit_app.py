#!/usr/bin/env python3
"""
Streamlit app for RAG Document Chat System
"""

import asyncio
import os
import streamlit as st

# Don't force demo mode - let config determine based on API key availability

from rag_system import RAGSystem

# Initialize RAG system
if 'rag_system' not in st.session_state:
    st.session_state.rag_system = RAGSystem()

rag_system = st.session_state.rag_system

# Streamlit Interface
st.set_page_config(
    page_title="RAG Document Chat",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“š RAG Document Chat System")
st.markdown("Upload documents and chat with them using AI!")

# File upload section
st.header("ğŸ“ Document Processing")

uploaded_file = st.file_uploader(
    "Choose a document",
    type=['pdf', 'txt'],
    help="Upload PDF or TXT files to add to your knowledge base"
)

if uploaded_file is not None:
    # Step 1: Basic Processing
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“„ Basic Chunks", use_container_width=True, help="Process into logical chunks"):
            with st.spinner("Creating logical chunks..."):
                try:
                    result = asyncio.run(rag_system.process_document(
                        uploaded_file.read(), uploaded_file.name
                    ))
                    
                    if result.status == "success":
                        st.success(f"âœ… {result.message}")
                        st.info(f"â±ï¸ Processed in {result.processing_time:.2f}s")
                        
                        # Store filename for step 2
                        st.session_state['last_processed_file'] = uploaded_file.name
                    else:
                        st.error(f"âŒ {result.message}")
                        
                except Exception as e:
                    st.error(f"âŒ Error: {str(e)}")
    
    # Step 2: Enhanced Processing (only available after step 1)
    with col2:
        if 'last_processed_file' in st.session_state and st.session_state['last_processed_file'] == uploaded_file.name:
            if st.button("ğŸ§  Smart Summaries", use_container_width=True, help="Add 10:1 compressed summaries"):
                with st.spinner("Creating smart summaries (10:1 compression)..."):
                    try:
                        result = asyncio.run(
                            rag_system.process_document_hierarchically(
                                uploaded_file.name
                            )
                        )
                        
                        if result.status == "success":
                            st.success(f"âœ… {result.message}")
                            
                            # Show compression stats
                            stats = result.compression_stats
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric(
                                    "Logical Groups", 
                                    result.logical_groups_created
                                )
                            
                            with col_b:
                                st.metric(
                                    "Compression Ratio", 
                                    f"{stats.get('overall_compression_ratio', 0):.1f}:1"
                                )
                            
                            with col_c:
                                st.metric(
                                    "Processing Time", 
                                    f"{result.total_processing_time:.1f}s"
                                )
                            
                            # Show word reduction
                            input_words = stats.get('total_input_words', 0)
                            output_words = stats.get('total_output_words', 0)
                            
                            st.info(f"ğŸ“Š Compressed {input_words:,} words â†’ {output_words:,} words")
                            
                        else:
                            st.error(f"âŒ {result.message}")
                            
                    except Exception as e:
                        st.error(f"âŒ Error: {str(e)}")
        else:
            st.button("ğŸ§  Smart Summaries", use_container_width=True, disabled=True, help="Process basic chunks first")
    
    # Step 3: Paragraph Processing (only available after step 1)
    with col3:
        if 'last_processed_file' in st.session_state and st.session_state['last_processed_file'] == uploaded_file.name:
            if st.button("ğŸ“ Paragraph Context", use_container_width=True, help="Create paragraph summaries for wider search context"):
                with st.spinner("Creating paragraph summaries (3:1 compression)..."):
                    try:
                        result = asyncio.run(
                            rag_system.process_document_paragraphs(
                                uploaded_file.name
                            )
                        )
                        
                        if result.status == "success":
                            st.success(f"âœ… {result.message}")
                            
                            # Show compression stats
                            stats = result.compression_stats
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric(
                                    "Paragraphs", 
                                    result.paragraphs_processed
                                )
                            
                            with col_b:
                                st.metric(
                                    "Compression", 
                                    f"{stats.get('overall_compression_ratio', 0):.1f}:1"
                                )
                            
                            with col_c:
                                st.metric(
                                    "Processing Time", 
                                    f"{result.total_processing_time:.1f}s"
                                )
                            
                            # Show word reduction
                            input_words = stats.get('total_input_words', 0)
                            output_words = stats.get('total_output_words', 0)
                            
                            st.info(f"ğŸ“„ Processed {input_words:,} words â†’ {output_words:,} words in paragraph summaries")
                            
                        else:
                            st.error(f"âŒ {result.message}")
                            
                    except Exception as e:
                        st.error(f"âŒ Error: {str(e)}")
        else:
            st.button("ğŸ“ Paragraph Context", use_container_width=True, disabled=True, help="Process basic chunks first")
    
    # Add processing status
    st.divider()
    st.subheader("ğŸ“Š Processing Status")
    
    # Check what collections exist
    try:
        basic_count = len(rag_system.clients.chromadb.get_or_create_collection("documents").get()['ids'])
        
        summary_count = 0
        try:
            summary_collection = rag_system.clients.chromadb.get_or_create_collection("logical_summaries")
            summary_count = len(summary_collection.get()['ids'])
        except:
            summary_count = 0
        
        paragraph_count = 0
        try:
            paragraph_collection = rag_system.clients.chromadb.get_or_create_collection("paragraph_summaries")
            paragraph_count = len(paragraph_collection.get()['ids'])
        except:
            paragraph_count = 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Basic Chunks", basic_count)
        with col2:
            st.metric("Smart Summaries", summary_count)
        with col3:
            st.metric("Paragraph Summaries", paragraph_count)
            
    except Exception as e:
        st.warning("Could not retrieve processing stats")


# Main chat interface
st.header("ğŸ’¬ Chat with Your Documents")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # Show sources for assistant messages
        if message["role"] == "assistant" and "sources" in message and message["sources"]:
            with st.expander("ğŸ“š Sources", expanded=False):
                for source in message["sources"]:
                    st.text(f"â€¢ {source}")

# Chat input
if prompt := st.chat_input("Ask a question about your documents..."):
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate assistant response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            try:
                try:
                    summary_collection = rag_system.clients.chromadb.get_or_create_collection("logical_summaries")
                    has_summaries = len(summary_collection.get()['ids']) > 0
                except:
                    has_summaries = False
                
                try:
                    paragraph_collection = rag_system.clients.chromadb.get_or_create_collection("paragraph_summaries")
                    has_paragraphs = len(paragraph_collection.get()['ids']) > 0
                except:
                    has_paragraphs = False
                
                if has_paragraphs:
                    response = rag_system.search_with_paragraphs(prompt, top_k_paragraphs=3, top_k_chunks=5)
                    st.caption("ğŸ“ Using paragraph context + detailed chunks")
                elif has_summaries:
                    response = rag_system.search_enhanced(prompt, top_k=8, use_summaries=True)
                    st.caption("ğŸ§  Using smart summaries + detailed chunks")
                else:
                    response = rag_system.search_and_answer(prompt, top_k=8)
                    st.caption("ğŸ“„ Using basic chunks only")
                
                # Display answer
                st.markdown(response.answer)
                
                # Add to chat history
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response.answer,
                    "sources": response.sources
                })
                
                # Show sources
                if response.sources:
                    with st.expander("ğŸ“š Sources", expanded=False):
                        for source in response.sources:
                            if source.startswith("Paragraph:"):
                                st.markdown(f"ğŸ“ {source}")
                            elif source.startswith("Summary:"):
                                st.markdown(f"ğŸ§  {source}")
                            else:
                                st.text(f"ğŸ“„ {source}")
                
                # Show processing time
                st.caption(f"â±ï¸ Response generated in {response.processing_time:.2f}s")
                
            except Exception as e:
                error_msg = f"Sorry, I encountered an error: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg,
                    "sources": []
                })

# Sidebar with system status
with st.sidebar:
    st.header("System Status")
    status = rag_system.get_system_status()
    
    for service, state in status.items():
        if state == "connected":
            st.success(f"âœ… {service.title()}: Connected")
        elif state == "error":
            st.error(f"âŒ {service.title()}: Error")
        elif state == "disabled":
            st.info(f"â„¹ï¸ {service.title()}: Disabled")
        else:
            st.warning(f"âš ï¸ {service.title()}: {state}")
    
    from config import config
    if config.demo_mode:
        st.info("ğŸ­ Running in Demo Mode")
        st.markdown("To use with real OpenAI API, set your API key in environment variables.")
    else:
        st.success("ğŸš€ Production Mode - OpenAI API Active")
        st.markdown("Using real OpenAI GPT models for responses.")